# Paper Presentations

## Language Modeling

### 01/23

* [Class-based N-gram Models of Natural Language](http://aclweb.org/anthology/J92-4003), Brown et al., CL, 1992. - [Victoria Lawlor](https://www.slideshare.net/jchoi7s/2019-classbased-ngram-models-of-natural-language) &#10003;

### 01/28

* [Latent Dirichlet Allocation](http://jmlr.csail.mit.edu/papers/v3/blei03a.html), Blei et al., JMLR, 2003. - Yikai Wang &#10003;


## Distributional Semantics

### 01/30

* [A Neural Probabilistic Language Model](https://papers.nips.cc/paper/1839-a-neural-probabilistic-language-model.pdf), Bengio et al., NIPS, 2000. - Weijian Li &#10003;
* [A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning](http://icml2008.cs.helsinki.fi/papers/391.pdf), Collobert and Weston, ICML, 2008. - Yuchun Liu Weijian

### 01/28

* [GloVe: Global Vectors for Word Representation](https://www.aclweb.org/anthology/D14-1162), Pennington et al., EMNLP, 2014. - Zelalem Gero Weijian &#10003;
* [Efficient Non-parametric Estimation of Multiple Embeddings per Word in Vector Space](https://aclweb.org/anthology/D14-1113), Neelakantan et al., EMNLP, 2014. -Xinyi Jiang Weijian &#10003;

### 02/06

* [Regularizing and Optimizing LSTM Language Models](https://openreview.net/pdf?id=SyyGPP0TZ), Merity et al., ICLR, 2018. - Xinyao Qian &#10003;
* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805), Devlin et al., arXiv, 2018. - Changmao Li &#10003;


## Document Classification

### 02/11

* [Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank](http://aclweb.org/anthology/D13-1170), Socher et al., EMNLP, 2013. - Hao Liu &#10003;

### 02/18

* [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](https://www.aclweb.org/anthology/P15-1150), Tai et al., ACL, 2015. - James Finch &#10003;
* [Very Deep Convolutional Networks for Text Classification](http://www.aclweb.org/anthology/E17-1104), Conneau et al., EACL, 2017. - Harshita Sahijwani &#10003;

### 02/20

* [A Helping Hand: Transfer Learning for Deep Sentiment Analysis](http://aclweb.org/anthology/P18-1235), Dong et al., ACL, 2018. - Jason Choi &#10003;
* [Linguistically Regularized LSTM for Sentiment Classification](http://www.aclweb.org/anthology/P17-1154), Qian et al., ACL, 2017. - Chen Lin &#10003;
* [A Hierarchical Neural Attention-based Text Classifier](http://aclweb.org/anthology/D18-1094), Sinha et al., EMNLP, 2018. -TBA


## Sequence Tagging

### 02/25

* [Word Representations: A Simple and General Method for Semi-Supervised Learning](http://www.aclweb.org/anthology/P10-1040), Turian et al., ACL, 2010. - Siwen Zhu &#10003;
* [Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data](https://repository.upenn.edu/cgi/viewcontent.cgi?article=1162&context=cis_papers), Lafferty et al., ICML, 2001. - Jing Zhang &#10003;

### 02/27

* [Named Entity Recognition with Bidirectional LSTM-CNNs](https://www.aclweb.org/anthology/Q16-1026), Chiu & Nichols, TACL, 2016. - Shaojun Yu &#10003;
* [Transfer Learning for Sequence Tagging with Hierarchical Recurrent Networks](https://arxiv.org/abs/1703.06345), Yang et al., ICLR, 2017. - Zhexiong Liu &#10003;
* [Semi-supervised Sequence Tagging with Bidirectional Language Models](http://www.aclweb.org/anthology/P17-1161), Peters et al., ACL, 2017. - TBA

### 03/04

* [Contextual String Embeddings for Sequence Labeling](http://aclweb.org/anthology/C18-1139), Akbik et al., COLING, 2018. - Wenji Yang


## Structure Parsing

### 03/04

* [Straight to the Tree: Constituency Parsing with Neural Syntactic Distance](http://aclweb.org/anthology/P18-1108), Shen et al., 2018. - Sihan Yue

### 03/06

* [Structured Training for Neural Network Transition-Based Parsing](http://aclweb.org/anthology/P15-1032), Weiss et al., ACL, 2015. - Yunsong Liu
* [Deep Biaffine Attention for Neural Dependency Parsing](https://arxiv.org/abs/1611.01734), Dozat and Manning, ICLR, 2017. - Han He
* [What's Going On in Neural Constituency Parsers? An Analysis](http://aclweb.org/anthology/N18-1091), Gaddy et al., NAACL, 2018. - TBA


### 03/27

* [End-to-end Learning of Semantic Role Labeling Using Recurrent Neural Networks](http://aclweb.org/anthology/P15-1109), Zhou and Xu, ACL, 2015. - Tianhao Liu
* [Deep Semantic Role Labeling: What Works and Whatâ€™s Next](http://aclweb.org/anthology/P17-1044), He et al., ACL, 2017. - Kate Li
* [AMR Parsing as Graph Prediction with Latent Alignment](http://aclweb.org/anthology/P18-1037), Lyu and Titov, ACL, 2018 - TBA.
* [Better Transition-Based AMR Parsing with a Refined Search Space](http://aclweb.org/anthology/D18-1198), Guo and Lu, EMNLP, 2018 - TBA.

## Entity Resolution

### 04/01

* [Learning Global Features for Coreference Resolution](https://aclweb.org/anthology/N16-1114), Wiseman et al., NAACL, 2016. - TBA
* [Improving Coreference Resolution by Learning Entity-Level Distributed Representations](http://www.aclweb.org/anthology/P16-1061), Clark and Manning, ACL, 2016. - TBA

### 04/03

* [End-to-end Neural Coreference Resolution](https://www.aclweb.org/anthology/D17-1018), Lee et al., EMNLP, 2017. - Liyan Xu
* [They Exist! Introducing Plural Mentions to Coreference Resolution and Entity Linking](http://aclweb.org/anthology/C18-1003), Zhou and Choi, COLING, 2018. - TBA

## Machine Comprehension

### 04/08

* R-NET: [Gated Self-Matching Networks for Reading Comprehension and Question Answering](http://www.aclweb.org/anthology/P17-1018), Wang et al., ACL, 2017. - TBA
* SLQA: [Multi-Granularity Hierarchical Attention Fusion Networks for Reading Comprehension and Question Answering](http://aclweb.org/anthology/P18-1158), Wang et al., ACL, 2018. - TBA
* [QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension](https://arxiv.org/abs/1804.09541), Yu et al., ICLR, 2018. - Zhengzhe Yang

### 04/10

* [A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task](https://www.aclweb.org/anthology/P16-1223), Chen et al., ACL, 2016. - Sarah Fillwock
* [Attention-over-Attention Neural Networks for Reading Comprehension](http://aclweb.org/anthology/P17-1055), Cui et al., ACL, 2017. - Yuan Zhao
* [Gated-Attention Readers for Text Comprehension](http://aclweb.org/anthology/P17-1168), Dhingra et al., ACL, 2017. - TBA

### 04/15

* SAN: [Stochastic Answer Networks for Machine Reading Comprehension](http://aclweb.org/anthology/P18-1157), Liu et al., ACL, 2018. - TBA
* [Attention-Guided Answer Distillation for Machine Reading Comprehension](http://aclweb.org/anthology/D18-1232), Hu et al., EMNLP, 2018. - TBA